{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOiftOR0B7xrpiq7XhuFP+K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVN1ef55O65K","executionInfo":{"status":"ok","timestamp":1754900981288,"user_tz":-210,"elapsed":53621,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}},"outputId":"60845410-87fd-4df0-85a0-3827faf4f8b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✅ Extracted dataset to: /content/dataset_V6\n","✅ CSV copied to: /content/dataset_V6.csv\n"]}],"source":["# Imports\n","import os\n","import random\n","import pandas as pd\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset, ConcatDataset, DataLoader\n","from torchvision import models\n","from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import functional as TF\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import multiprocessing\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from sklearn.utils.class_weight import compute_class_weight\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import seaborn as sns\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","# Step 1: Mount Google Drive\n","# drive.mount('/content/drive')\n","drive.mount(\"/content/drive\", force_remount=True)\n","# Step 2: Define paths (edit these if needed)\n","zip_path = \"/content/drive/MyDrive/dataset_V6.zip\"  # <-- change this if your file is in a folder\n","extract_dir = \"/content/dataset_V6\"\n","\n","# Step 3: Unzip the dataset\n","import zipfile\n","\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_dir)\n","\n","print(f\"✅ Extracted dataset to: {extract_dir}\")\n","\n","\n","\n","# Step 4 (Optional): Copy the CSV if it's also on Drive\n","# If your CSV is in MyDrive, adjust the path accordingly\n","\n","csv_drive_path = \"/content/drive/MyDrive/dataset_V6.csv\"\n","csv_colab_path = \"/content/dataset_V6.csv\"\n","\n","!cp \"{csv_drive_path}\" \"{csv_colab_path}\"\n","\n","print(f\"✅ CSV copied to: {csv_colab_path}\")\n","\n","\n"]},{"cell_type":"code","source":["# class PadToSquareWithMean:\n","#     def __call__(self, image):\n","#         w, h = image.size\n","#         max_dim = max(w, h)\n","#         pad_left = (max_dim - w) // 2\n","#         pad_top = (max_dim - h) // 2\n","#         pad_right = max_dim - w - pad_left\n","#         pad_bottom = max_dim - h - pad_top\n","\n","#         # Compute true mean color\n","#         np_img = np.array(image)\n","#         mean_color = tuple(np_img.reshape(-1, 3).mean(axis=0).astype(np.uint8))\n","\n","#         return TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom),\n","#                       fill=mean_color, padding_mode='constant')\n","\n","CSV_PATH = \"dataset_V6.csv\"\n","IMAGE_DIR = \"/content/dataset_V6/dataset_V6\"\n","\n","# # ===== Base + Augmentation Transforms =====\n","# base_transform = transforms.Compose([\n","#     PadToSquareWithMean(),\n","#     transforms.Resize((300, 300)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","#                          std=[0.229, 0.224, 0.225])  # standard ImageNet normalization\n","# ])\n","\n","# aug_transform = transforms.Compose([\n","#     PadToSquareWithMean(),\n","#     transforms.Resize((300, 300)),\n","#     transforms.RandomRotation(25),\n","#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n","#     transforms.RandomAffine(15, translate=(0.1,0.1)),\n","#     # transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","#                          std=[0.229, 0.224, 0.225])\n","# ])\n","\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","\n","# ---------- Utils ----------\n","def _mean_rgb(image: Image.Image):\n","    arr = np.array(image.convert(\"RGB\"))\n","    return tuple(arr.reshape(-1, 3).mean(axis=0).astype(np.uint8).tolist())\n","\n","class PadToSquareWithMean:\n","    def __call__(self, image: Image.Image):\n","        w, h = image.size\n","        max_dim = max(w, h)\n","        pad_left  = (max_dim - w) // 2\n","        pad_top   = (max_dim - h) // 2\n","        pad_right = max_dim - w - pad_left\n","        pad_bottom= max_dim - h - pad_top\n","        mean_color = _mean_rgb(image)\n","        return TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom),\n","                      fill=mean_color, padding_mode='constant')\n","\n","class RotateWithMeanFill:\n","    def __init__(self, degrees=12):\n","        self.degrees = degrees\n","    def __call__(self, image: Image.Image):\n","        angle = transforms.RandomRotation.get_params([-self.degrees, self.degrees])\n","        mean_color = _mean_rgb(image)\n","        # expand=False keeps size; corners are filled with mean_color\n","        return TF.rotate(image, angle=angle, expand=False, fill=mean_color)\n","\n","class AffineWithMeanFill:\n","    \"\"\"\n","    Mild translation/scale/shear with mean-color fill.\n","    Set degrees if you want an extra tiny shear rotation; otherwise keep 0.\n","    \"\"\"\n","    def __init__(self, degrees=0, translate=(0.08, 0.08), scale=(0.95, 1.05), shear=(-5, 5)):\n","        self.degrees = degrees\n","        self.translate = translate\n","        self.scale = scale\n","        self.shear = shear\n","\n","    def __call__(self, image: Image.Image):\n","        # sample params the same way torchvision does\n","        angle, translations, scale, shear = transforms.RandomAffine.get_params(\n","            degrees=(-self.degrees, self.degrees),\n","            translate=self.translate,\n","            scale_ranges=self.scale,\n","            shears=self.shear,\n","            img_size=image.size\n","        )\n","        mean_color = _mean_rgb(image)\n","        return TF.affine(\n","            image,\n","            angle=angle,\n","            translate=translations,\n","            scale=scale,\n","            shear=shear,\n","            interpolation=transforms.InterpolationMode.BILINEAR,\n","            fill=mean_color\n","        )\n","\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD  = [0.229, 0.224, 0.225]\n","\n","# ---------- Base (no aug) ----------\n","base_transform = transforms.Compose([\n","    PadToSquareWithMean(),\n","    transforms.Resize((260, 260)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","])\n","\n","# ---------- Augmented (train) ----------\n","aug_transform = transforms.Compose([\n","    PadToSquareWithMean(),\n","    transforms.Resize((260, 260)),\n","\n","    # Geometry (keep mild/realistic for microscope images)\n","    RotateWithMeanFill(degrees=12),              # ~±12°\n","    transforms.RandomHorizontalFlip(p=0.3),      # set to 0 if orientation-critical\n","    transforms.RandomVerticalFlip(p=0.1),        # consider disabling if S/I matters\n","    AffineWithMeanFill(\n","        degrees=0,                               # keep 0 unless you want extra tiny rotation\n","        translate=(0.10, 0.10),\n","        scale=(0.95, 1.05),\n","        shear=(-4, 4)\n","    ),\n","\n","    # Photometric\n","    transforms.RandomApply([\n","        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.10)\n","    ], p=0.6),\n","\n","    # Light blur (focus drift)\n","    transforms.RandomApply([\n","        transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 1.2))\n","    ], p=0.3),\n","\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","\n","    # Occlusion (simulates tools, glare, bubbles)\n","    transforms.RandomErasing(\n","        p=0.25,\n","        scale=(0.02, 0.08),\n","        ratio=(0.3, 3.3),\n","        value='random'\n","    ),\n","])\n","\n","# ========== Dataset ==========\n","class CataractDataset(Dataset):\n","    def __init__(self, dataframe, image_dir, transform=None):\n","        self.data = dataframe.reset_index(drop=True)\n","        self.image_dir = image_dir\n","        self.transform = transform\n","        self.label_map = {\"low\": 0, \"moderate\": 1, \"high\": 2, \"mature\": 3, \"poor dilation\": 4}\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        img_path = os.path.join(self.image_dir, row[\"filename\"] + \".jpg\")\n","        try:\n","            image = Image.open(img_path).convert(\"RGB\")\n","        except FileNotFoundError:\n","            print(f\"Missing image: {img_path}\")\n","            return self.__getitem__((idx + 1) % len(self.data))\n","\n","        label = self.label_map[row[\"label\"].lower()]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, torch.tensor(label)\n","\n","# ========== Load and Prepare CSV ==========\n","df = pd.read_csv(CSV_PATH)\n","df.columns = df.columns.str.strip()\n","df.rename(columns={\"Frame Name\": \"filename\"}, inplace=True)\n","\n","# Derive label column from binary indicators\n","df[\"label\"] = None\n","df.loc[df[\"Low Nuclear Density\"] == 1.0, \"label\"] = \"low\"\n","df.loc[df[\"Moderate Nuclear Density\"] == 1.0, \"label\"] = \"moderate\"\n","df.loc[df[\"High Nuclear Density\"] == 1.0, \"label\"] = \"high\"\n","df.loc[df[\"Mature\"] == 1.0, \"label\"] = \"mature\"\n","df.loc[df[\"Poor Dilation\"] == 1.0, \"label\"] = \"poor dilation\"\n","\n","\n","# Keep only valid rows\n","df = df[df[\"label\"].notna()]\n","df = df[[\"filename\", \"label\"]]\n","# ========= Balance Function =========\n","def balance_dataset(df, image_dir, target_per_class =800):\n","    datasets = []\n","    class_counts = df['label'].value_counts().to_dict()\n","    augmented_summary = {}\n","\n","    for label, count in class_counts.items():\n","        class_df = df[df['label'] == label]\n","\n","        # Keep all original samples\n","        datasets.append(CataractDataset(class_df, image_dir, transform=base_transform))\n","\n","        # Only add augmentation if class is below target\n","        if count < target_per_class:\n","            needed = target_per_class - count\n","            aug_rows = class_df.sample(needed, replace=True, random_state=42)\n","            datasets.append(CataractDataset(aug_rows, image_dir, transform=aug_transform))\n","            augmented_summary[label] = needed\n","        else:\n","            augmented_summary[label] = 0  # nothing added\n","\n","    balanced_dataset = ConcatDataset(datasets)\n","\n","    # Print summary\n","    print(\"\\n=== Balancing Summary (No Downsampling) ===\")\n","    for label, count in class_counts.items():\n","        added = augmented_summary[label]\n","        final_count = count + added\n","        print(f\"{label:15s} | Original: {count:4d} | Added: {added:4d} | Final: {final_count:4d}\")\n","    print(f\"\\nTotal balanced dataset size: {len(balanced_dataset)}\")\n","\n","    return balanced_dataset\n","\n","\n","df = pd.read_csv(CSV_PATH)\n","df.columns = df.columns.str.strip()\n","df.rename(columns={\"Frame Name\": \"filename\"}, inplace=True)\n","\n","# Derive labels from binary indicators\n","df[\"label\"] = None\n","df.loc[df[\"Low Nuclear Density\"] == 1.0, \"label\"] = \"low\"\n","df.loc[df[\"Moderate Nuclear Density\"] == 1.0, \"label\"] = \"moderate\"\n","df.loc[df[\"High Nuclear Density\"] == 1.0, \"label\"] = \"high\"\n","df.loc[df[\"Mature\"] == 1.0, \"label\"] = \"mature\"\n","df.loc[df[\"Poor Dilation\"] == 1.0, \"label\"] = \"poor dilation\"\n","\n","df = df[df[\"label\"].notna()]\n","df = df[[\"filename\", \"label\"]]\n","\n","# ========= Split Dataset =========\n","train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n","\n","print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n","\n","# ========= Create Datasets =========\n","train_dataset = balance_dataset(train_df, IMAGE_DIR, target_per_class=800)\n","val_dataset = CataractDataset(val_df, IMAGE_DIR, transform=base_transform)\n","test_dataset = CataractDataset(test_df, IMAGE_DIR, transform=base_transform)\n","\n","# ========= Create DataLoaders =========\n","BATCH_SIZE = 64\n","num_cpu = multiprocessing.cpu_count()\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_cpu//2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_cpu//2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_cpu//2, pin_memory=True)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vh0tLH4BPfnt","executionInfo":{"status":"ok","timestamp":1754900981290,"user_tz":-210,"elapsed":22,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}},"outputId":"45f7610c-3743-41f4-eea6-ead743c9e182"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 1404, Val: 301, Test: 301\n","\n","=== Balancing Summary (No Downsampling) ===\n","mature          | Original:  367 | Added:  433 | Final:  800\n","low             | Original:  323 | Added:  477 | Final:  800\n","high            | Original:  298 | Added:  502 | Final:  800\n","poor dilation   | Original:  251 | Added:  549 | Final:  800\n","moderate        | Original:  165 | Added:  635 | Final:  800\n","\n","Total balanced dataset size: 4000\n"]}]},{"cell_type":"code","source":["def efficientnet_b3(num_classes=5, pretrained=True, phase=\"warmup\"):\n","    \"\"\"\n","    EfficientNet-B3 with progressive fine-tuning.\n","\n","    Parameters\n","    ----------\n","    num_classes : int\n","        Number of output classes.\n","    pretrained : bool\n","        Whether to load ImageNet pretrained weights.\n","    phase : str\n","        \"warmup\"   → train only classifier\n","        \"partial\"  → unfreeze last 2 feature blocks + classifier\n","        \"full\"     → train all layers\n","\n","    Returns\n","    -------\n","    model : nn.Module\n","    \"\"\"\n","    weights = models.EfficientNet_B3_Weights.DEFAULT if pretrained else None\n","    model = models.efficientnet_b3(weights=weights)\n","\n","    # Replace final classifier\n","    in_feats = model.classifier[1].in_features\n","    model.classifier[1] = nn.Linear(in_feats, num_classes)\n","\n","    # Freeze all parameters initially\n","    for name, param in model.named_parameters():\n","        param.requires_grad = False\n","\n","        if phase == \"warmup\" and name.startswith(\"classifier\"):\n","            param.requires_grad = True\n","\n","        # EfficientNet-B3 has 8 feature blocks (features.0 through features.8)\n","        elif phase == \"partial\" and name.startswith((\"features.7\", \"features.8\", \"classifier\")):\n","            param.requires_grad = True\n","\n","        elif phase == \"full\":\n","            param.requires_grad = True\n","\n","    return model\n"],"metadata":{"id":"umMl93zXPmk8","executionInfo":{"status":"ok","timestamp":1754900981290,"user_tz":-210,"elapsed":15,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def efficientnet_b2(num_classes=5, pretrained=True, phase=\"warmup\"):\n","    \"\"\"\n","    EfficientNet-B2 with progressive fine-tuning.\n","\n","    Parameters\n","    ----------\n","    num_classes : int\n","        Number of output classes.\n","    pretrained : bool\n","        Whether to load ImageNet pretrained weights.\n","    phase : str\n","        \"warmup\"   → train only classifier\n","        \"partial\"  → unfreeze last 2 feature blocks + classifier\n","        \"full\"     → train all layers\n","\n","    Returns\n","    -------\n","    model : nn.Module\n","    \"\"\"\n","    weights = models.EfficientNet_B2_Weights.DEFAULT if pretrained else None\n","    model = models.efficientnet_b2(weights=weights)\n","\n","    # Replace final classifier\n","    in_feats = model.classifier[1].in_features\n","    model.classifier[1] = nn.Linear(in_feats, num_classes)\n","\n","    # Set requires_grad depending on phase\n","    for name, param in model.named_parameters():\n","        param.requires_grad = False  # freeze everything first\n","\n","        if phase == \"warmup\" and name.startswith(\"classifier\"):\n","            param.requires_grad = True\n","\n","        elif phase == \"partial\" and name.startswith((\"features.6\", \"features.7\", \"classifier\")):\n","            param.requires_grad = True\n","\n","        elif phase == \"full\":\n","            param.requires_grad = True\n","\n","    return model\n"],"metadata":{"id":"gJIJTwO4P7Zu","executionInfo":{"status":"ok","timestamp":1754900981291,"user_tz":-210,"elapsed":14,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**B2**\n"],"metadata":{"id":"_UH9WfRDQBfD"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # ===== EfficientNet with Progressive Phases =====\n","# def efficientnet_b2(num_classes=5, pretrained=True, phase=\"warmup\"):\n","#     weights = models.EfficientNet_B2_Weights.DEFAULT if pretrained else None\n","#     model = models.efficientnet_b2(weights=weights)\n","\n","#     # Replace classifier\n","#     in_feats = model.classifier[1].in_features\n","#     model.classifier[1] = nn.Linear(in_feats, num_classes)\n","\n","#     # Freeze/unfreeze according to phase\n","#     for name, param in model.named_parameters():\n","#         param.requires_grad = False\n","\n","#         if phase == \"warmup\" and name.startswith(\"classifier\"):\n","#             param.requires_grad = True\n","#         elif phase == \"partial\" and name.startswith((\"features.6\", \"features.7\", \"classifier\")):\n","#             param.requires_grad = True\n","#         elif phase == \"full\":\n","#             param.requires_grad = True\n","\n","#     return model\n","\n","# ===== Training Utilities =====\n","def train_one_epoch(model, loader, optimizer, criterion, epoch, total_epochs, phase_name):\n","    model.train()\n","    running_loss, preds_all, labels_all = 0.0, [], []\n","    total_steps = len(loader)\n","\n","    for step, (images, labels) in enumerate(loader, 1):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        preds_all.extend(outputs.argmax(1).cpu().numpy())\n","        labels_all.extend(labels.cpu().numpy())\n","\n","        # Print per-step loss\n","        if (step+1) % 5 == 0:\n","          print(f\"[{phase_name} | Epoch {epoch}/{total_epochs} | Step {step}/{total_steps}] \"\n","              f\"Step Loss: {loss.item():.4f}\")\n","\n","\n","    acc = accuracy_score(labels_all, preds_all)\n","    f1 = f1_score(labels_all, preds_all, average=\"weighted\")\n","    return running_loss / len(loader.dataset), acc, f1, labels_all, preds_all\n","\n","\n","def evaluate(model, loader, criterion):\n","    model.eval()\n","    running_loss, preds_all, labels_all, probs_all = 0.0, [], [], []\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * images.size(0)\n","            preds_all.extend(outputs.argmax(1).cpu().numpy())\n","            labels_all.extend(labels.cpu().numpy())\n","            probs_all.extend(F.softmax(outputs, dim=1).cpu().numpy())\n","\n","    acc = accuracy_score(labels_all, preds_all)\n","    f1 = f1_score(labels_all, preds_all, average=\"weighted\")\n","    return running_loss / len(loader.dataset), acc, f1, labels_all, preds_all, probs_all\n","\n","\n","def progressive_training(train_loader, val_loader, num_classes=5):\n","    phases = [\n","        {\"name\": \"warmup\", \"epochs\": 10, \"lr\": 1e-3},\n","        {\"name\": \"partial\", \"epochs\": 15, \"lr\": 5e-5},\n","        {\"name\": \"full\", \"epochs\": 20, \"lr\": 5e-6},\n","    ]\n","\n","    criterion = nn.CrossEntropyLoss()\n","    prev_phase = None\n","\n","    all_train_losses = []\n","    all_val_losses = []\n","\n","    for phase in phases:\n","        print(f\"\\n=== Phase: {phase['name']} ===\")\n","\n","        if prev_phase is None:\n","            # model = efficientnet_b2(num_classes=num_classes, phase=\"warmup\").to(device)\n","            model = efficientnet_b3(num_classes=num_classes, phase=\"warmup\").to(device)\n","            # model = EfficientNetB2WithDropout(num_classes=num_classes, phase=\"warmup\").to(device)\n","\n","        else:\n","            # model = efficientnet_b2(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            # model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","            model = efficientnet_b3(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","            # model = EfficientNetB2WithDropout(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            # model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","        # optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n","        #                        lr=phase[\"lr\"], weight_decay=1e-4)\n","\n","        optimizer = optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()),\n","        lr=phase[\"lr\"],              # keep the LR from your phase config\n","        weight_decay=1e-4            # same weight decay you used before\n","        )\n","\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n","\n","        # # T_max is the number of epochs over which to anneal from initial lr → eta_min\n","        # scheduler = CosineAnnealingLR(\n","        #     optimizer,\n","        #     T_max=phase[\"epochs\"],\n","        #     eta_min=1e-6,    # floor learning rate\n","        #     last_epoch=-1    # start from scratch each phase\n","        # )\n","\n","        best_val_loss = np.inf\n","        patience, patience_counter = 3, 0\n","\n","        for epoch in range(1, phase[\"epochs\"] + 1):\n","            train_loss, train_acc, train_f1, y_train, y_pred_train = train_one_epoch(\n","                model, train_loader, optimizer, criterion, epoch, phase[\"epochs\"], phase[\"name\"])\n","            val_loss, val_acc, val_f1, y_val, y_pred_val, y_proba_val = evaluate(\n","                model, val_loader, criterion)\n","\n","            # # update LR scheduler\n","            # if isinstance(scheduler, ReduceLROnPlateau):\n","            #     scheduler.step(val_loss)\n","            # else:\n","            #     scheduler.step()\n","\n","            # scheduler.step()\n","\n","            all_train_losses.append(train_loss)\n","            all_val_losses.append(val_loss)\n","\n","            # End of epoch summary\n","            print(f\"Epoch [{epoch}/{phase['epochs']}], \"\n","                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n","                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n","\n","            # Early stopping\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","                torch.save(model.state_dict(), f\"best_model_{phase['name']}.pth\")\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= patience:\n","                    print(\"Early stopping triggered.\")\n","                    break\n","\n","        # ---- After each phase: Per-class metrics ----\n","        print(f\"\\n=== Detailed Metrics for Phase: {phase['name']} ===\")\n","        print(classification_report(y_val, y_pred_val, target_names=[\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"]))\n","\n","        cm = confusion_matrix(y_val, y_pred_val)\n","        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                                      display_labels=[\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"])\n","        disp.plot(cmap=\"Blues\")\n","        plt.show()\n","\n","        # ROC-AUC (One-vs-Rest)\n","        try:\n","            roc_auc = roc_auc_score(y_val, y_proba_val, multi_class=\"ovr\")\n","            print(f\"ROC-AUC: {roc_auc:.4f}\")\n","        except ValueError:\n","            print(\"ROC-AUC could not be computed (need probabilities for all classes).\")\n","\n","        prev_phase = phase[\"name\"]\n","\n","\n","    plt.figure(figsize=(8,6))\n","    plt.plot(all_train_losses, label=\"Train Loss\")\n","    plt.plot(all_val_losses, label=\"Validation Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Training vs Validation Loss\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    print(\"\\nTraining complete. Best models for each phase saved.\")\n","    return model\n"],"metadata":{"id":"CnJNilCcP8VS","executionInfo":{"status":"ok","timestamp":1754901020366,"user_tz":-210,"elapsed":512,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = progressive_training(train_loader, val_loader, num_classes=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"n9EEWSKqQFWb","executionInfo":{"status":"error","timestamp":1754901279335,"user_tz":-210,"elapsed":257728,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}},"outputId":"386e6523-a137-4711-d388-083f19171992"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Phase: warmup ===\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n","100%|██████████| 47.2M/47.2M [00:00<00:00, 199MB/s]\n","/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[warmup | Epoch 1/10 | Step 4/63] Step Loss: 1.6084\n","[warmup | Epoch 1/10 | Step 9/63] Step Loss: 1.5448\n","[warmup | Epoch 1/10 | Step 14/63] Step Loss: 1.5209\n","[warmup | Epoch 1/10 | Step 19/63] Step Loss: 1.4779\n","[warmup | Epoch 1/10 | Step 24/63] Step Loss: 1.4301\n","[warmup | Epoch 1/10 | Step 29/63] Step Loss: 1.4803\n","[warmup | Epoch 1/10 | Step 34/63] Step Loss: 1.4153\n","[warmup | Epoch 1/10 | Step 39/63] Step Loss: 1.4237\n","[warmup | Epoch 1/10 | Step 44/63] Step Loss: 1.3002\n","[warmup | Epoch 1/10 | Step 49/63] Step Loss: 1.4043\n","[warmup | Epoch 1/10 | Step 54/63] Step Loss: 1.3893\n","[warmup | Epoch 1/10 | Step 59/63] Step Loss: 1.3715\n","Epoch [1/10], Train Loss: 1.4289, Acc: 0.4427, F1: 0.4403 | Val Loss: 1.2807, Acc: 0.5648, F1: 0.5632\n","[warmup | Epoch 2/10 | Step 4/63] Step Loss: 1.2726\n","[warmup | Epoch 2/10 | Step 9/63] Step Loss: 1.2719\n","[warmup | Epoch 2/10 | Step 14/63] Step Loss: 1.2524\n","[warmup | Epoch 2/10 | Step 19/63] Step Loss: 1.2225\n","[warmup | Epoch 2/10 | Step 24/63] Step Loss: 1.2719\n","[warmup | Epoch 2/10 | Step 29/63] Step Loss: 1.2447\n","[warmup | Epoch 2/10 | Step 34/63] Step Loss: 1.0614\n","[warmup | Epoch 2/10 | Step 39/63] Step Loss: 1.1573\n","[warmup | Epoch 2/10 | Step 44/63] Step Loss: 1.1400\n","[warmup | Epoch 2/10 | Step 49/63] Step Loss: 1.0593\n","[warmup | Epoch 2/10 | Step 54/63] Step Loss: 1.1423\n","[warmup | Epoch 2/10 | Step 59/63] Step Loss: 1.0427\n","Epoch [2/10], Train Loss: 1.1833, Acc: 0.5895, F1: 0.5871 | Val Loss: 1.1496, Acc: 0.5947, F1: 0.5914\n","[warmup | Epoch 3/10 | Step 4/63] Step Loss: 1.1862\n","[warmup | Epoch 3/10 | Step 9/63] Step Loss: 1.2218\n","[warmup | Epoch 3/10 | Step 14/63] Step Loss: 1.0649\n","[warmup | Epoch 3/10 | Step 19/63] Step Loss: 1.0944\n","[warmup | Epoch 3/10 | Step 24/63] Step Loss: 1.1213\n","[warmup | Epoch 3/10 | Step 29/63] Step Loss: 1.1343\n","[warmup | Epoch 3/10 | Step 34/63] Step Loss: 1.2543\n","[warmup | Epoch 3/10 | Step 39/63] Step Loss: 1.0429\n","[warmup | Epoch 3/10 | Step 44/63] Step Loss: 1.1634\n","[warmup | Epoch 3/10 | Step 49/63] Step Loss: 1.0484\n","[warmup | Epoch 3/10 | Step 54/63] Step Loss: 1.1782\n","[warmup | Epoch 3/10 | Step 59/63] Step Loss: 1.1025\n","Epoch [3/10], Train Loss: 1.0895, Acc: 0.6188, F1: 0.6158 | Val Loss: 1.0902, Acc: 0.6179, F1: 0.6185\n","[warmup | Epoch 4/10 | Step 4/63] Step Loss: 1.1209\n","[warmup | Epoch 4/10 | Step 9/63] Step Loss: 1.0526\n","[warmup | Epoch 4/10 | Step 14/63] Step Loss: 0.9906\n","[warmup | Epoch 4/10 | Step 19/63] Step Loss: 1.0515\n","[warmup | Epoch 4/10 | Step 24/63] Step Loss: 1.0264\n","[warmup | Epoch 4/10 | Step 29/63] Step Loss: 0.9011\n","[warmup | Epoch 4/10 | Step 34/63] Step Loss: 1.0167\n","[warmup | Epoch 4/10 | Step 39/63] Step Loss: 0.9742\n","[warmup | Epoch 4/10 | Step 44/63] Step Loss: 0.9725\n","[warmup | Epoch 4/10 | Step 49/63] Step Loss: 1.0531\n","[warmup | Epoch 4/10 | Step 54/63] Step Loss: 0.9311\n","[warmup | Epoch 4/10 | Step 59/63] Step Loss: 0.9570\n","Epoch [4/10], Train Loss: 1.0182, Acc: 0.6282, F1: 0.6260 | Val Loss: 1.0454, Acc: 0.6346, F1: 0.6298\n","[warmup | Epoch 5/10 | Step 4/63] Step Loss: 1.1262\n","[warmup | Epoch 5/10 | Step 9/63] Step Loss: 1.0334\n","[warmup | Epoch 5/10 | Step 14/63] Step Loss: 1.0064\n","[warmup | Epoch 5/10 | Step 19/63] Step Loss: 0.9059\n","[warmup | Epoch 5/10 | Step 24/63] Step Loss: 1.1578\n","[warmup | Epoch 5/10 | Step 29/63] Step Loss: 0.9460\n","[warmup | Epoch 5/10 | Step 34/63] Step Loss: 0.9824\n","[warmup | Epoch 5/10 | Step 39/63] Step Loss: 0.9379\n","[warmup | Epoch 5/10 | Step 44/63] Step Loss: 0.9039\n","[warmup | Epoch 5/10 | Step 49/63] Step Loss: 0.9905\n","[warmup | Epoch 5/10 | Step 54/63] Step Loss: 0.9663\n","[warmup | Epoch 5/10 | Step 59/63] Step Loss: 1.1736\n","Epoch [5/10], Train Loss: 0.9871, Acc: 0.6368, F1: 0.6345 | Val Loss: 1.0308, Acc: 0.6279, F1: 0.6267\n","[warmup | Epoch 6/10 | Step 4/63] Step Loss: 0.9814\n","[warmup | Epoch 6/10 | Step 9/63] Step Loss: 1.0734\n","[warmup | Epoch 6/10 | Step 14/63] Step Loss: 0.9622\n","[warmup | Epoch 6/10 | Step 19/63] Step Loss: 1.0040\n","[warmup | Epoch 6/10 | Step 24/63] Step Loss: 0.9749\n","[warmup | Epoch 6/10 | Step 29/63] Step Loss: 0.8670\n","[warmup | Epoch 6/10 | Step 34/63] Step Loss: 0.9883\n","[warmup | Epoch 6/10 | Step 39/63] Step Loss: 0.9118\n","[warmup | Epoch 6/10 | Step 44/63] Step Loss: 0.9154\n","[warmup | Epoch 6/10 | Step 49/63] Step Loss: 0.7459\n","[warmup | Epoch 6/10 | Step 54/63] Step Loss: 0.9756\n","[warmup | Epoch 6/10 | Step 59/63] Step Loss: 0.9274\n","Epoch [6/10], Train Loss: 0.9455, Acc: 0.6555, F1: 0.6549 | Val Loss: 0.9985, Acc: 0.6279, F1: 0.6221\n","[warmup | Epoch 7/10 | Step 4/63] Step Loss: 0.8475\n","[warmup | Epoch 7/10 | Step 9/63] Step Loss: 0.8429\n","[warmup | Epoch 7/10 | Step 14/63] Step Loss: 0.8306\n","[warmup | Epoch 7/10 | Step 19/63] Step Loss: 0.7728\n","[warmup | Epoch 7/10 | Step 24/63] Step Loss: 0.8820\n","[warmup | Epoch 7/10 | Step 29/63] Step Loss: 0.9862\n","[warmup | Epoch 7/10 | Step 34/63] Step Loss: 0.8132\n","[warmup | Epoch 7/10 | Step 39/63] Step Loss: 0.8017\n","[warmup | Epoch 7/10 | Step 44/63] Step Loss: 0.9765\n","[warmup | Epoch 7/10 | Step 49/63] Step Loss: 0.9027\n","[warmup | Epoch 7/10 | Step 54/63] Step Loss: 0.8821\n","[warmup | Epoch 7/10 | Step 59/63] Step Loss: 0.9496\n","Epoch [7/10], Train Loss: 0.9198, Acc: 0.6687, F1: 0.6677 | Val Loss: 0.9879, Acc: 0.6412, F1: 0.6426\n","[warmup | Epoch 8/10 | Step 4/63] Step Loss: 0.8413\n","[warmup | Epoch 8/10 | Step 9/63] Step Loss: 0.7928\n","[warmup | Epoch 8/10 | Step 14/63] Step Loss: 0.9280\n","[warmup | Epoch 8/10 | Step 19/63] Step Loss: 0.8088\n","[warmup | Epoch 8/10 | Step 24/63] Step Loss: 0.9237\n","[warmup | Epoch 8/10 | Step 29/63] Step Loss: 1.0470\n","[warmup | Epoch 8/10 | Step 34/63] Step Loss: 0.9522\n","[warmup | Epoch 8/10 | Step 39/63] Step Loss: 0.9035\n","[warmup | Epoch 8/10 | Step 44/63] Step Loss: 0.9374\n","[warmup | Epoch 8/10 | Step 49/63] Step Loss: 0.7832\n","[warmup | Epoch 8/10 | Step 54/63] Step Loss: 0.9639\n","[warmup | Epoch 8/10 | Step 59/63] Step Loss: 0.9347\n","Epoch [8/10], Train Loss: 0.8928, Acc: 0.6827, F1: 0.6822 | Val Loss: 0.9685, Acc: 0.6113, F1: 0.6033\n","[warmup | Epoch 9/10 | Step 4/63] Step Loss: 0.7903\n","[warmup | Epoch 9/10 | Step 9/63] Step Loss: 0.7736\n","[warmup | Epoch 9/10 | Step 14/63] Step Loss: 0.7592\n","[warmup | Epoch 9/10 | Step 19/63] Step Loss: 0.9382\n","[warmup | Epoch 9/10 | Step 24/63] Step Loss: 0.8495\n","[warmup | Epoch 9/10 | Step 29/63] Step Loss: 0.7550\n","[warmup | Epoch 9/10 | Step 34/63] Step Loss: 0.8903\n","[warmup | Epoch 9/10 | Step 39/63] Step Loss: 0.9271\n","[warmup | Epoch 9/10 | Step 44/63] Step Loss: 0.9927\n","[warmup | Epoch 9/10 | Step 49/63] Step Loss: 0.7540\n","[warmup | Epoch 9/10 | Step 54/63] Step Loss: 0.9271\n","[warmup | Epoch 9/10 | Step 59/63] Step Loss: 0.9042\n","Epoch [9/10], Train Loss: 0.8840, Acc: 0.6790, F1: 0.6785 | Val Loss: 0.9685, Acc: 0.6246, F1: 0.6134\n","[warmup | Epoch 10/10 | Step 4/63] Step Loss: 0.8549\n","[warmup | Epoch 10/10 | Step 9/63] Step Loss: 0.9798\n","[warmup | Epoch 10/10 | Step 14/63] Step Loss: 0.8516\n","[warmup | Epoch 10/10 | Step 19/63] Step Loss: 0.9760\n","[warmup | Epoch 10/10 | Step 24/63] Step Loss: 0.8889\n","[warmup | Epoch 10/10 | Step 29/63] Step Loss: 0.9827\n","[warmup | Epoch 10/10 | Step 34/63] Step Loss: 0.8645\n","[warmup | Epoch 10/10 | Step 39/63] Step Loss: 0.8438\n","[warmup | Epoch 10/10 | Step 44/63] Step Loss: 0.8779\n","[warmup | Epoch 10/10 | Step 49/63] Step Loss: 0.8455\n","[warmup | Epoch 10/10 | Step 54/63] Step Loss: 0.8421\n","[warmup | Epoch 10/10 | Step 59/63] Step Loss: 0.7831\n","Epoch [10/10], Train Loss: 0.8674, Acc: 0.6817, F1: 0.6811 | Val Loss: 0.9535, Acc: 0.6412, F1: 0.6433\n","\n","=== Detailed Metrics for Phase: warmup ===\n","               precision    recall  f1-score   support\n","\n","          low       0.63      0.74      0.68        70\n","     moderate       0.62      0.58      0.60        36\n","         high       0.45      0.48      0.46        63\n","       mature       0.72      0.73      0.73        78\n","poor dilation       0.87      0.61      0.72        54\n","\n","     accuracy                           0.64       301\n","    macro avg       0.66      0.63      0.64       301\n"," weighted avg       0.66      0.64      0.64       301\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ROC-AUC: 0.8788\n","\n","=== Phase: partial ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[partial | Epoch 1/15 | Step 4/63] Step Loss: 0.7641\n","[partial | Epoch 1/15 | Step 9/63] Step Loss: 0.8040\n","[partial | Epoch 1/15 | Step 14/63] Step Loss: 0.8050\n","[partial | Epoch 1/15 | Step 19/63] Step Loss: 0.7270\n","[partial | Epoch 1/15 | Step 24/63] Step Loss: 0.9301\n","[partial | Epoch 1/15 | Step 29/63] Step Loss: 0.8102\n","[partial | Epoch 1/15 | Step 34/63] Step Loss: 0.9034\n","[partial | Epoch 1/15 | Step 39/63] Step Loss: 0.8048\n","[partial | Epoch 1/15 | Step 44/63] Step Loss: 0.6646\n","[partial | Epoch 1/15 | Step 49/63] Step Loss: 0.7194\n"]},{"output_type":"stream","name":"stderr","text":["Exception in thread Thread-25 (_pin_memory_loop):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n","    do_one_step()\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n","    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n","    return _ForkingPickler.loads(res)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n","    fd = df.detach()\n","         ^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n","    with _resource_sharer.get_connection(self._id) as conn:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n","    c = Client(address, authkey=process.current_process().authkey)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n","    c = SocketClient(address)\n","        ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n","    s.connect(address)\n","FileNotFoundError: [Errno 2] No such file or directory\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1154077756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogressive_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1695534711.py\u001b[0m in \u001b[0;36mprogressive_training\u001b[0;34m(train_loader, val_loader, num_classes)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             train_loss, train_acc, train_f1, y_train, y_pred_train = train_one_epoch(\n\u001b[0m\u001b[1;32m    126\u001b[0m                 model, train_loader, optimizer, criterion, epoch, phase[\"epochs\"], phase[\"name\"])\n\u001b[1;32m    127\u001b[0m             val_loss, val_acc, val_f1, y_val, y_pred_val, y_proba_val = evaluate(\n","\u001b[0;32m/tmp/ipython-input-1695534711.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion, epoch, total_epochs, phase_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mpreds_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlabels_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["**B3**"],"metadata":{"id":"EynetDl5QIvm"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # ===== EfficientNet with Progressive Phases =====\n","# def efficientnet_b2(num_classes=5, pretrained=True, phase=\"warmup\"):\n","#     weights = models.EfficientNet_B2_Weights.DEFAULT if pretrained else None\n","#     model = models.efficientnet_b2(weights=weights)\n","\n","#     # Replace classifier\n","#     in_feats = model.classifier[1].in_features\n","#     model.classifier[1] = nn.Linear(in_feats, num_classes)\n","\n","#     # Freeze/unfreeze according to phase\n","#     for name, param in model.named_parameters():\n","#         param.requires_grad = False\n","\n","#         if phase == \"warmup\" and name.startswith(\"classifier\"):\n","#             param.requires_grad = True\n","#         elif phase == \"partial\" and name.startswith((\"features.6\", \"features.7\", \"classifier\")):\n","#             param.requires_grad = True\n","#         elif phase == \"full\":\n","#             param.requires_grad = True\n","\n","#     return model\n","\n","# ===== Training Utilities =====\n","def train_one_epoch(model, loader, optimizer, criterion, epoch, total_epochs, phase_name):\n","    model.train()\n","    running_loss, preds_all, labels_all = 0.0, [], []\n","    total_steps = len(loader)\n","\n","    for step, (images, labels) in enumerate(loader, 1):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        preds_all.extend(outputs.argmax(1).cpu().numpy())\n","        labels_all.extend(labels.cpu().numpy())\n","\n","        # Print per-step loss\n","        if (step+1) % 5 == 0:\n","          print(f\"[{phase_name} | Epoch {epoch}/{total_epochs} | Step {step}/{total_steps}] \"\n","              f\"Step Loss: {loss.item():.4f}\")\n","\n","\n","    acc = accuracy_score(labels_all, preds_all)\n","    f1 = f1_score(labels_all, preds_all, average=\"weighted\")\n","    return running_loss / len(loader.dataset), acc, f1, labels_all, preds_all\n","\n","\n","def evaluate(model, loader, criterion):\n","    model.eval()\n","    running_loss, preds_all, labels_all, probs_all = 0.0, [], [], []\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * images.size(0)\n","            preds_all.extend(outputs.argmax(1).cpu().numpy())\n","            labels_all.extend(labels.cpu().numpy())\n","            probs_all.extend(F.softmax(outputs, dim=1).cpu().numpy())\n","\n","    acc = accuracy_score(labels_all, preds_all)\n","    f1 = f1_score(labels_all, preds_all, average=\"weighted\")\n","    return running_loss / len(loader.dataset), acc, f1, labels_all, preds_all, probs_all\n","\n","\n","def progressive_training(train_loader, val_loader, num_classes=5):\n","    phases = [\n","        {\"name\": \"warmup\", \"epochs\": 10, \"lr\": 1e-3},\n","        {\"name\": \"partial\", \"epochs\": 15, \"lr\": 5e-5},\n","        {\"name\": \"full\", \"epochs\": 20, \"lr\": 5e-6},\n","    ]\n","\n","    criterion = nn.CrossEntropyLoss()\n","    prev_phase = None\n","\n","    all_train_losses = []\n","    all_val_losses = []\n","\n","    for phase in phases:\n","        print(f\"\\n=== Phase: {phase['name']} ===\")\n","\n","        if prev_phase is None:\n","            model = efficientnet_b2(num_classes=num_classes, phase=\"warmup\").to(device)\n","            # model = efficientnet_b3(num_classes=num_classes, phase=\"warmup\").to(device)\n","            # model = EfficientNetB2WithDropout(num_classes=num_classes, phase=\"warmup\").to(device)\n","\n","        else:\n","            model = efficientnet_b2(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","            # model = efficientnet_b3(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            # model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","            # model = EfficientNetB2WithDropout(num_classes=num_classes, phase=phase[\"name\"]).to(device)\n","            # model.load_state_dict(torch.load(f\"best_model_{prev_phase}.pth\"))\n","        # optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n","        #                        lr=phase[\"lr\"], weight_decay=1e-4)\n","\n","        optimizer = optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()),\n","        lr=phase[\"lr\"],              # keep the LR from your phase config\n","        weight_decay=1e-4            # same weight decay you used before\n","        )\n","\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n","\n","        # # T_max is the number of epochs over which to anneal from initial lr → eta_min\n","        # scheduler = CosineAnnealingLR(\n","        #     optimizer,\n","        #     T_max=phase[\"epochs\"],\n","        #     eta_min=1e-6,    # floor learning rate\n","        #     last_epoch=-1    # start from scratch each phase\n","        # )\n","\n","        best_val_loss = np.inf\n","        patience, patience_counter = 3, 0\n","\n","        for epoch in range(1, phase[\"epochs\"] + 1):\n","            train_loss, train_acc, train_f1, y_train, y_pred_train = train_one_epoch(\n","                model, train_loader, optimizer, criterion, epoch, phase[\"epochs\"], phase[\"name\"])\n","            val_loss, val_acc, val_f1, y_val, y_pred_val, y_proba_val = evaluate(\n","                model, val_loader, criterion)\n","\n","            # # update LR scheduler\n","            # if isinstance(scheduler, ReduceLROnPlateau):\n","            #     scheduler.step(val_loss)\n","            # else:\n","            #     scheduler.step()\n","\n","            # scheduler.step()\n","\n","            all_train_losses.append(train_loss)\n","            all_val_losses.append(val_loss)\n","\n","            # End of epoch summary\n","            print(f\"Epoch [{epoch}/{phase['epochs']}], \"\n","                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n","                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n","\n","            # Early stopping\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","                torch.save(model.state_dict(), f\"best_model_{phase['name']}.pth\")\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= patience:\n","                    print(\"Early stopping triggered.\")\n","                    break\n","\n","        # ---- After each phase: Per-class metrics ----\n","        print(f\"\\n=== Detailed Metrics for Phase: {phase['name']} ===\")\n","        print(classification_report(y_val, y_pred_val, target_names=[\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"]))\n","\n","        cm = confusion_matrix(y_val, y_pred_val)\n","        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                                      display_labels=[\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"])\n","        disp.plot(cmap=\"Blues\")\n","        plt.show()\n","\n","        # ROC-AUC (One-vs-Rest)\n","        try:\n","            roc_auc = roc_auc_score(y_val, y_proba_val, multi_class=\"ovr\")\n","            print(f\"ROC-AUC: {roc_auc:.4f}\")\n","        except ValueError:\n","            print(\"ROC-AUC could not be computed (need probabilities for all classes).\")\n","\n","        prev_phase = phase[\"name\"]\n","\n","\n","    plt.figure(figsize=(8,6))\n","    plt.plot(all_train_losses, label=\"Train Loss\")\n","    plt.plot(all_val_losses, label=\"Validation Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Training vs Validation Loss\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    print(\"\\nTraining complete. Best models for each phase saved.\")\n","    return model\n"],"metadata":{"id":"7YxmnAcNQKXa","executionInfo":{"status":"aborted","timestamp":1754901279336,"user_tz":-210,"elapsed":5,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = progressive_training(train_loader, val_loader, num_classes=5)"],"metadata":{"id":"mUwvDS-qQOh6","executionInfo":{"status":"aborted","timestamp":1754901279336,"user_tz":-210,"elapsed":5,"user":{"displayName":"yazdan bayat","userId":"05989392580614465732"}}},"execution_count":null,"outputs":[]}]}