{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nMuas2DXN5di"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-156480858.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Step 1: Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# drive.mount('/content/drive')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 29\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m# Step 2: Define paths (edit these if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/dataset_V6.zip\"\u001b[0m  \u001b[0;31m# \u003c-- change this if your file is in a folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--\u003e 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["# Imports\n","import os\n","import random\n","import pandas as pd\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset, ConcatDataset, DataLoader\n","from torchvision import models\n","from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import functional as TF\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import multiprocessing\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from sklearn.utils.class_weight import compute_class_weight\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import seaborn as sns\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","# Step 1: Mount Google Drive\n","# drive.mount('/content/drive')\n","drive.mount(\"/content/drive\", force_remount=True)\n","# Step 2: Define paths (edit these if needed)\n","zip_path = \"/content/drive/MyDrive/dataset_V6.zip\"  # \u003c-- change this if your file is in a folder\n","extract_dir = \"/content/dataset_V6\"\n","\n","# Step 3: Unzip the dataset\n","import zipfile\n","\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_dir)\n","\n","print(f\"✅ Extracted dataset to: {extract_dir}\")\n","\n","\n","\n","\n","# Step 4 (Optional): Copy the CSV if it's also on Drive\n","# If your CSV is in MyDrive, adjust the path accordingly\n","\n","csv_drive_path = \"/content/drive/MyDrive/dataset_V6.csv\"\n","csv_colab_path = \"/content/dataset_V6.csv\"\n","\n","!cp \"{csv_drive_path}\" \"{csv_colab_path}\"\n","\n","print(f\"✅ CSV copied to: {csv_colab_path}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-_hpSUfnOLjl"},"outputs":[],"source":["# class PadToSquareWithMean:\n","#     def __call__(self, image):\n","#         w, h = image.size\n","#         max_dim = max(w, h)\n","#         pad_left = (max_dim - w) // 2\n","#         pad_top = (max_dim - h) // 2\n","#         pad_right = max_dim - w - pad_left\n","#         pad_bottom = max_dim - h - pad_top\n","\n","#         # Compute true mean color\n","#         np_img = np.array(image)\n","#         mean_color = tuple(np_img.reshape(-1, 3).mean(axis=0).astype(np.uint8))\n","\n","#         return TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom),\n","#                       fill=mean_color, padding_mode='constant')\n","\n","CSV_PATH = \"dataset_V6.csv\"\n","IMAGE_DIR = \"/content/dataset_V6/dataset_V6\"\n","\n","# # ===== Base + Augmentation Transforms =====\n","# base_transform = transforms.Compose([\n","#     PadToSquareWithMean(),\n","#     transforms.Resize((300, 300)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","#                          std=[0.229, 0.224, 0.225])  # standard ImageNet normalization\n","# ])\n","\n","# aug_transform = transforms.Compose([\n","#     PadToSquareWithMean(),\n","#     transforms.Resize((300, 300)),\n","#     transforms.RandomRotation(25),\n","#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n","#     transforms.RandomAffine(15, translate=(0.1,0.1)),\n","#     # transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","#                          std=[0.229, 0.224, 0.225])\n","# ])\n","\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","\n","# ---------- Utils ----------\n","def _mean_rgb(image: Image.Image):\n","    arr = np.array(image.convert(\"RGB\"))\n","    return tuple(arr.reshape(-1, 3).mean(axis=0).astype(np.uint8).tolist())\n","\n","class PadToSquareWithMean:\n","    def __call__(self, image: Image.Image):\n","        w, h = image.size\n","        max_dim = max(w, h)\n","        pad_left  = (max_dim - w) // 2\n","        pad_top   = (max_dim - h) // 2\n","        pad_right = max_dim - w - pad_left\n","        pad_bottom= max_dim - h - pad_top\n","        mean_color = _mean_rgb(image)\n","        return TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom),\n","                      fill=mean_color, padding_mode='constant')\n","\n","class RotateWithMeanFill:\n","    def __init__(self, degrees=12):\n","        self.degrees = degrees\n","    def __call__(self, image: Image.Image):\n","        angle = transforms.RandomRotation.get_params([-self.degrees, self.degrees])\n","        mean_color = _mean_rgb(image)\n","        # expand=False keeps size; corners are filled with mean_color\n","        return TF.rotate(image, angle=angle, expand=False, fill=mean_color)\n","\n","class AffineWithMeanFill:\n","    \"\"\"\n","    Mild translation/scale/shear with mean-color fill.\n","    Set degrees if you want an extra tiny shear rotation; otherwise keep 0.\n","    \"\"\"\n","    def __init__(self, degrees=0, translate=(0.08, 0.08), scale=(0.95, 1.05), shear=(-5, 5)):\n","        self.degrees = degrees\n","        self.translate = translate\n","        self.scale = scale\n","        self.shear = shear\n","\n","    def __call__(self, image: Image.Image):\n","        # sample params the same way torchvision does\n","        angle, translations, scale, shear = transforms.RandomAffine.get_params(\n","            degrees=(-self.degrees, self.degrees),\n","            translate=self.translate,\n","            scale_ranges=self.scale,\n","            shears=self.shear,\n","            img_size=image.size\n","        )\n","        mean_color = _mean_rgb(image)\n","        return TF.affine(\n","            image,\n","            angle=angle,\n","            translate=translations,\n","            scale=scale,\n","            shear=shear,\n","            interpolation=transforms.InterpolationMode.BILINEAR,\n","            fill=mean_color\n","        )\n","\n","IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD  = [0.229, 0.224, 0.225]\n","\n","# ---------- Base (no aug) ----------\n","base_transform = transforms.Compose([\n","    PadToSquareWithMean(),\n","    transforms.Resize((260, 260)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","])\n","\n","# ---------- Augmented (train) ----------\n","aug_transform = transforms.Compose([\n","    PadToSquareWithMean(),\n","    transforms.Resize((260, 260)),\n","\n","    # Geometry (keep mild/realistic for microscope images)\n","    RotateWithMeanFill(degrees=12),              # ~±12°\n","    transforms.RandomHorizontalFlip(p=0.3),      # set to 0 if orientation-critical\n","    transforms.RandomVerticalFlip(p=0.1),        # consider disabling if S/I matters\n","    AffineWithMeanFill(\n","        degrees=0,                               # keep 0 unless you want extra tiny rotation\n","        translate=(0.10, 0.10),\n","        scale=(0.95, 1.05),\n","        shear=(-4, 4)\n","    ),\n","\n","    # Photometric\n","    transforms.RandomApply([\n","        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.10)\n","    ], p=0.6),\n","\n","    # Light blur (focus drift)\n","    transforms.RandomApply([\n","        transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 1.2))\n","    ], p=0.3),\n","\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","\n","    # Occlusion (simulates tools, glare, bubbles)\n","    transforms.RandomErasing(\n","        p=0.25,\n","        scale=(0.02, 0.08),\n","        ratio=(0.3, 3.3),\n","        value='random'\n","    ),\n","])\n","\n","# ========== Dataset ==========\n","class CataractDataset(Dataset):\n","    def __init__(self, dataframe, image_dir, transform=None):\n","        self.data = dataframe.reset_index(drop=True)\n","        self.image_dir = image_dir\n","        self.transform = transform\n","        self.label_map = {\"low\": 0, \"moderate\": 1, \"high\": 2, \"mature\": 3, \"poor dilation\": 4}\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        img_path = os.path.join(self.image_dir, row[\"filename\"] + \".jpg\")\n","        try:\n","            image = Image.open(img_path).convert(\"RGB\")\n","        except FileNotFoundError:\n","            print(f\"Missing image: {img_path}\")\n","            return self.__getitem__((idx + 1) % len(self.data))\n","\n","        label = self.label_map[row[\"label\"].lower()]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, torch.tensor(label)\n","\n","# ========== Load and Prepare CSV ==========\n","df = pd.read_csv(CSV_PATH)\n","df.columns = df.columns.str.strip()\n","df.rename(columns={\"Frame Name\": \"filename\"}, inplace=True)\n","\n","# Derive label column from binary indicators\n","df[\"label\"] = None\n","df.loc[df[\"Low Nuclear Density\"] == 1.0, \"label\"] = \"low\"\n","df.loc[df[\"Moderate Nuclear Density\"] == 1.0, \"label\"] = \"moderate\"\n","df.loc[df[\"High Nuclear Density\"] == 1.0, \"label\"] = \"high\"\n","df.loc[df[\"Mature\"] == 1.0, \"label\"] = \"mature\"\n","df.loc[df[\"Poor Dilation\"] == 1.0, \"label\"] = \"poor dilation\"\n","\n","\n","# Keep only valid rows\n","df = df[df[\"label\"].notna()]\n","df = df[[\"filename\", \"label\"]]\n","# ========= Balance Function =========\n","def balance_dataset(df, image_dir, target_per_class =800):\n","    datasets = []\n","    class_counts = df['label'].value_counts().to_dict()\n","    augmented_summary = {}\n","\n","    for label, count in class_counts.items():\n","        class_df = df[df['label'] == label]\n","\n","        # Keep all original samples\n","        datasets.append(CataractDataset(class_df, image_dir, transform=base_transform))\n","\n","        # Only add augmentation if class is below target\n","        if count \u003c target_per_class:\n","            needed = target_per_class - count\n","            aug_rows = class_df.sample(needed, replace=True, random_state=42)\n","            datasets.append(CataractDataset(aug_rows, image_dir, transform=aug_transform))\n","            augmented_summary[label] = needed\n","        else:\n","            augmented_summary[label] = 0  # nothing added\n","\n","    balanced_dataset = ConcatDataset(datasets)\n","\n","    # Print summary\n","    print(\"\\n=== Balancing Summary (No Downsampling) ===\")\n","    for label, count in class_counts.items():\n","        added = augmented_summary[label]\n","        final_count = count + added\n","        print(f\"{label:15s} | Original: {count:4d} | Added: {added:4d} | Final: {final_count:4d}\")\n","    print(f\"\\nTotal balanced dataset size: {len(balanced_dataset)}\")\n","\n","    return balanced_dataset\n","\n","\n","df = pd.read_csv(CSV_PATH)\n","df.columns = df.columns.str.strip()\n","df.rename(columns={\"Frame Name\": \"filename\"}, inplace=True)\n","\n","# Derive labels from binary indicators\n","df[\"label\"] = None\n","df.loc[df[\"Low Nuclear Density\"] == 1.0, \"label\"] = \"low\"\n","df.loc[df[\"Moderate Nuclear Density\"] == 1.0, \"label\"] = \"moderate\"\n","df.loc[df[\"High Nuclear Density\"] == 1.0, \"label\"] = \"high\"\n","df.loc[df[\"Mature\"] == 1.0, \"label\"] = \"mature\"\n","df.loc[df[\"Poor Dilation\"] == 1.0, \"label\"] = \"poor dilation\"\n","\n","df = df[df[\"label\"].notna()]\n","df = df[[\"filename\", \"label\"]]\n","\n","# ========= Split Dataset =========\n","train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n","\n","print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n","\n","# ========= Create Datasets =========\n","train_dataset = balance_dataset(train_df, IMAGE_DIR, target_per_class=800)\n","val_dataset = CataractDataset(val_df, IMAGE_DIR, transform=base_transform)\n","test_dataset = CataractDataset(test_df, IMAGE_DIR, transform=base_transform)\n","\n","# ========= Create DataLoaders =========\n","BATCH_SIZE = 64\n","num_cpu = multiprocessing.cpu_count()\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_cpu//2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_cpu//2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_cpu//2, pin_memory=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kYqYmyecPPWO"},"outputs":[],"source":["import torch.nn as nn\n","from torchvision import models\n","\n","def efficientnet_b3(weights=\"DEFAULT\", fine_tune=True):\n","    \"\"\"\n","    EfficientNet-B3 adapted to 5 classes.\n","\n","    Parameters\n","    ----------\n","    weights : str | torchvision.models.EfficientNet_B3_Weights | None\n","        \"DEFAULT\"  → ImageNet-1K weights (torchvision ≥0.15).\n","        None       → random initialization.\n","        Or pass an explicit EfficientNet_B3_Weights enum.\n","    fine_tune : bool\n","        True  → freeze everything except last two MBConv blocks + classifier.\n","        False → leave all layers trainable.\n","\n","    Returns\n","    -------\n","    model : nn.Module\n","    \"\"\"\n","\n","    # 1) Load backbone\n","    eff_weights = (\n","        models.EfficientNet_B3_Weights.DEFAULT if weights == \"DEFAULT\" else weights\n","    )\n","    model = models.efficientnet_b3(weights=eff_weights)\n","\n","    # 2) Freeze / unfreeze\n","    if fine_tune:\n","        for p in model.parameters():\n","            p.requires_grad = False\n","        # Unfreeze the deepest layers (features.6 \u0026 features.7) and the classifier\n","        for name, p in model.named_parameters():\n","            if name.startswith((\"features.6\", \"features.7\", \"classifier\")):\n","                p.requires_grad = True\n","\n","    # 3) Replace classifier head\n","    in_feats = model.classifier[1].in_features\n","    model.classifier[1] = nn.Linear(in_feats, 5)   # 5 classes\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jVBLVZaCOOhw"},"outputs":[],"source":["CSV_PATH = \"/content/dataset_V6.csv\"\n","IMAGE_DIR = \"/content/dataset_V6/dataset_V6\"\n","\n","# train_loader, val_loader, test_loader, class_weights_tensor, df = get_dataloaders()\n","\n","\n","# Params\n","num_epochs = 60\n","lr = 1e-3\n","patience = 8\n","min_delta = 1e-4\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","\n","\n","# Print dataset statistics\n","print(f\"Total number of samples: {len(df)}\")\n","print(\"\\nClass distribution:\")\n","print(df['label'].value_counts())\n","\n","# Define the class labels (ordered)\n","classes = [\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"]\n","\n","# Create a subplot grid: 4 rows (classes) x 3 columns (images)\n","fig, axs = plt.subplots(len(classes), 3, figsize=(12, 10))\n","fig.suptitle(\"Sample Images per Class\", fontsize=16)\n","\n","# Loop over each class\n","for i, cls in enumerate(classes):\n","    class_samples = df[df[\"label\"] == cls].head(3)\n","    for j, (_, row) in enumerate(class_samples.iterrows()):\n","        img_path = os.path.join(IMAGE_DIR, row[\"filename\"] + \".jpg\")\n","        try:\n","            image = Image.open(img_path)\n","            axs[i, j].imshow(image)\n","            axs[i, j].axis(\"off\")\n","            axs[i, j].set_title(f\"{cls.capitalize()}\")\n","        except FileNotFoundError:\n","            axs[i, j].axis(\"off\")\n","            axs[i, j].set_title(\"Image not found\")\n","\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # adjust for suptitle\n","plt.show()\n","\n","# Plot bar chart of class distribution\n","plt.figure(figsize=(8, 5))\n","df[\"label\"].value_counts().sort_index().plot(kind='bar', color='skyblue')\n","plt.title(\"Class Distribution\")\n","plt.xlabel(\"Class\")\n","plt.ylabel(\"Number of Samples\")\n","plt.xticks(rotation=0)\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","\n","# Training\n","# model = resnet18(fine_tune=False).to(device)  # change to True if you want to fine-tune deeper layers\n","model = efficientnet_b3(fine_tune=True).to(device)\n","# Loss Function\n","# class_weights_tensor = class_weights_tensor.to(device)  # move to GPU\n","# loss_fn = torch.nn.CrossEntropyLoss()\n","loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n","\n","# Optimizer\n","# optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr)\n","# optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n","\n","optimizer = torch.optim.AdamW([\n","    {\"params\": model.features.parameters(), \"lr\": 3e-5},   # very small LR for backbone\n","    {\"params\": model.classifier.parameters(), \"lr\": 3e-4}  # higher LR for classifier\n","], weight_decay=1e-4)\n","\n","# Scheduler\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n","\n","\n","train_loss = []\n","valid_loss = []\n","\n","print(f\"Model is on device: {next(model.parameters()).device}\")\n","\n","# Train Loop\n","num_steps = len(train_loader)\n","for epochs in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for j, (imgs, lbls) in enumerate(train_loader):\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        optimizer.zero_grad()\n","        out = model(imgs)\n","        loss = loss_fn(out, lbls)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        if j % 2 == 0:\n","            print('Epoch: [{}/{}] | Step: [{}/{}] | Loss: {:.6f}'\n","                  .format(epochs+1, num_epochs, j+1, num_steps, loss.item()))\n","    train_loss.append(running_loss / num_steps)\n","    print('Epoch: [{}/{}] | Loss: {:.6f}'\n","          .format(epochs+1, num_epochs, loss.item()))\n","\n","#---------------------\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        running_valid_loss = 0.0\n","        for imgs, lbls in val_loader:\n","            imgs, lbls = imgs.to(device), lbls.to(device)\n","            out = model(imgs)\n","            loss_val = loss_fn(out, lbls)\n","            running_valid_loss += loss_val.item()\n","            predicted = torch.argmax(out, dim=1)\n","            correct += (predicted == lbls).sum().item()\n","            total += lbls.size(0)\n","        avg_val_loss = running_valid_loss / len(val_loader)\n","        valid_loss.append(avg_val_loss)\n","        print('Valid Loss: {:.6f} | Acc: {:.4f}'.format(valid_loss[-1], correct / total))\n","\n","        # Step the scheduler\n","        # scheduler.step(avg_val_loss)\n","\n","\n","        # Early stopping\n","        if best_val_loss - avg_val_loss \u003e min_delta:\n","            best_val_loss = avg_val_loss\n","            epochs_no_improve = 0\n","        else:\n","            epochs_no_improve += 1\n","            if epochs_no_improve \u003e= patience:\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","# Plot losses\n","plt.plot(range(1, len(train_loss)+1), train_loss, label='Train Loss')\n","plt.plot(range(1, len(valid_loss)+1), valid_loss, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training vs Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","\n","\n","\n","# # Predictions and true labels\n","# all_preds = []\n","# all_labels = []\n","#\n","# model.eval()\n","# with torch.no_grad():\n","#     for imgs, lbls in test_loader:\n","#         imgs = imgs.to(device)\n","#         outputs = model(imgs)\n","#         preds = torch.argmax(outputs, dim=1).cpu()\n","#         all_preds.extend(preds.numpy())\n","#         all_labels.extend(lbls.numpy())\n","#\n","# # Classification Report\n","# print(classification_report(all_labels, all_preds, target_names=classes))\n","#\n","# # Confusion Matrix\n","# cm = confusion_matrix(all_labels, all_preds)\n","# plt.figure(figsize=(10, 8))\n","# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n","# plt.xlabel('Predicted')\n","# plt.ylabel('True')\n","# plt.title('Confusion Matrix')\n","# plt.show()\n","#\n","\n","\n","# Evaluation\n","all_preds = []\n","all_labels = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for imgs, lbls in test_loader:\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        outputs = model(imgs)\n","        preds = torch.argmax(outputs, dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(lbls.cpu().numpy())\n","\n","# Convert to numpy arrays\n","all_preds = np.array(all_preds)\n","all_labels = np.array(all_labels)\n","\n","# Print classification report\n","report = classification_report(all_labels, all_preds, target_names=classes, digits=4)\n","print(report)\n","\n","# Save report as a dataframe (optional)\n","report_df = pd.DataFrame(classification_report(all_labels, all_preds, target_names=classes, output_dict=True)).T\n","report_df.to_csv(\"classification_report.csv\")\n","\n","# Accuracy and F1 scores\n","print(f\"\\nOverall Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n","print(f\"Macro F1-score  : {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n","print(f\"Weighted F1-score: {f1_score(all_labels, all_preds, average='weighted'):.4f}\")\n","\n","# Confusion Matrix\n","cm = confusion_matrix(all_labels, all_preds)\n","cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","# Plot raw confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix (Raw Counts)')\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot normalized confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens', xticklabels=classes, yticklabels=classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix (Normalized)')\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","torch.save(model.state_dict(), \"efficientnet_b2_cataract.pth\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MrSpKlmEORbq"},"outputs":[],"source":["# --- 0) No-aug train loader for feature extraction ---\n","# Use the same base_transform you already use for val/test\n","feat_dataset = CataractDataset(train_df.reset_index(drop=True), IMAGE_DIR, transform=base_transform)\n","feat_loader  = DataLoader(feat_dataset, batch_size=64, shuffle=False,\n","                          num_workers=num_cpu//2, pin_memory=True)\n","\n","# If you need label names in a fixed order:\n","classes = [\"low\", \"moderate\", \"high\", \"mature\", \"poor dilation\"]\n","name_to_idx = {c:i for i,c in enumerate(classes)}\n","\n","# --- 1) Collect penultimate-layer embeddings with a hook ---\n","import torch\n","import numpy as np\n","\n","model.eval()\n","emb_chunks, lab_chunks = [], []\n","\n","# For torchvision/timm EfficientNet, the classifier is in model.classifier (Sequential[Dropout, Linear]).\n","# A forward *pre*-hook on `classifier` gives the tensor right before the head = penultimate embedding.\n","def _feat_hook(module, inputs):\n","    # inputs is a tuple; take the tensor [B, D]\n","    x = inputs[0].detach().cpu()\n","    emb_chunks.append(x)\n","\n","hook_handle = model.classifier.register_forward_pre_hook(lambda m, inp: _feat_hook(m, inp))\n","\n","with torch.no_grad():\n","    for imgs, lbls in feat_loader:\n","        imgs = imgs.to(device)\n","        _ = model(imgs)                      # forward pass triggers the hook\n","        lab_chunks.append(lbls.cpu())\n","\n","# Clean up the hook\n","hook_handle.remove()\n","\n","embeddings = torch.cat(emb_chunks, dim=0).numpy()       # [N, D]\n","labels     = torch.cat(lab_chunks, dim=0).numpy()       # [N]\n","\n","print(\"Embeddings shape:\", embeddings.shape, \" | Labels:\", labels.shape)\n","\n","# --- 2) t-SNE (PCA -\u003e t-SNE is faster/stabler) ---\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","\n","X_pca  = PCA(n_components=min(50, embeddings.shape[1]-1), random_state=42).fit_transform(embeddings)\n","tsne   = TSNE(n_components=2, perplexity=30, init='pca', learning_rate='auto', random_state=42)\n","X_2d   = tsne.fit_transform(X_pca)                       # [N, 2]\n","\n","# --- 3) Plot ---\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","plt.figure(figsize=(8,6))\n","num_classes = len(classes)\n","cmap = matplotlib.cm.get_cmap('tab10', num_classes)\n","for idx, cls in enumerate(classes):\n","    mask = (labels == idx)\n","    plt.scatter(X_2d[mask,0], X_2d[mask,1], s=12, alpha=0.7, label=cls, color=cmap(idx))\n","\n","plt.title(\"t-SNE of Train Embeddings (penultimate layer)\")\n","plt.xlabel(\"t-SNE 1\"); plt.ylabel(\"t-SNE 2\")\n","plt.legend(markerscale=1.5, fontsize=9, frameon=False)\n","plt.tight_layout()\n","plt.show()\n","\n","# (Optional) Save for later analysis\n","import pandas as pd\n","tsne_df = pd.DataFrame({\"x\": X_2d[:,0], \"y\": X_2d[:,1], \"label\": [classes[i] for i in labels]})\n","tsne_df.to_csv(\"tsne_train_embeddings.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"84BvXh_aOfo4"},"outputs":[],"source":["# ===== 0) Test loader (no augmentation) =====\n","test_dataset = CataractDataset(test_df.reset_index(drop=True), IMAGE_DIR, transform=base_transform)\n","test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False,\n","                          num_workers=max(0, num_cpu//2), pin_memory=True)\n","\n","# ===== 1) Helper: collect penultimate embeddings via a pre-hook on model.classifier =====\n","import torch\n","import numpy as np\n","\n","def collect_penultimate_embeddings(model, loader, device):\n","    model.eval()\n","    emb_chunks, lab_chunks = [], []\n","\n","    def _feat_hook(module, inputs):\n","        x = inputs[0].detach().cpu()  # [B, D] entering the final Linear\n","        emb_chunks.append(x)\n","\n","    handle = model.classifier.register_forward_pre_hook(lambda m, inp: _feat_hook(m, inp))\n","    try:\n","        with torch.no_grad():\n","            for imgs, lbls in loader:\n","                imgs = imgs.to(device)\n","                _ = model(imgs)              # triggers the hook\n","                lab_chunks.append(lbls.cpu())\n","    finally:\n","        handle.remove()\n","\n","    embeddings = torch.cat(emb_chunks, dim=0).numpy()   # [N, D]\n","    labels     = torch.cat(lab_chunks, dim=0).numpy()   # [N]\n","    return embeddings, labels\n","\n","embeddings_test, labels_test = collect_penultimate_embeddings(model, test_loader, device)\n","print(\"Test embeddings:\", embeddings_test.shape, \"labels:\", labels_test.shape)\n","\n","# ===== 2) PCA -\u003e t-SNE =====\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","\n","D = embeddings_test.shape[1]\n","n_pca = max(2, min(50, D - 1))  # safe bounds\n","X_pca = PCA(n_components=n_pca, random_state=42).fit_transform(embeddings_test)\n","\n","tsne = TSNE(n_components=2, perplexity=30, init='pca', learning_rate='auto', random_state=42)\n","X2_test = tsne.fit_transform(X_pca)  # [N, 2]\n","\n","# ===== 3) Plot =====\n","import matplotlib.pyplot as plt\n","import matplotlib\n","\n","plt.figure(figsize=(8, 6))\n","num_classes = len(classes)\n","cmap = matplotlib.cm.get_cmap('tab10', num_classes)\n","\n","for idx, cls in enumerate(classes):\n","    mask = (labels_test == idx)\n","    plt.scatter(X2_test[mask, 0], X2_test[mask, 1], s=12, alpha=0.7, label=cls, color=cmap(idx))\n","\n","plt.title(\"t-SNE of Test Embeddings (penultimate layer)\")\n","plt.xlabel(\"t-SNE 1\"); plt.ylabel(\"t-SNE 2\")\n","plt.legend(markerscale=1.5, fontsize=9, frameon=False)\n","plt.tight_layout()\n","plt.savefig(\"tsne_test_plot.png\", dpi=200)\n","plt.show()\n","\n","# ===== 4) Save CSV =====\n","import pandas as pd\n","tsne_test_df = pd.DataFrame({\n","    \"x\": X2_test[:, 0],\n","    \"y\": X2_test[:, 1],\n","    \"label\": [classes[i] for i in labels_test]\n","})\n","tsne_test_df.to_csv(\"tsne_test_embeddings.csv\", index=False)\n","print(\"Saved: tsne_test_embeddings.csv and tsne_test_plot.png\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2SdLCPVN5l5/GMp1zEscw","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}